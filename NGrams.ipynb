{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import glob, os\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk import bigrams, trigrams, word_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "os.chdir(\"../quoteAIsData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 4 gram N-Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"DAVID\", \"DIEGO\", \"ERIC\", \"GWYN\", \"JETT\", \"MARS\", \"MILES\", \"MILO\", \"PARSA\"]\n",
    "def safe_insert_list(dictionary, key, value):\n",
    "    if key in dictionary:\n",
    "        dictionary[key].append(value)\n",
    "    else:\n",
    "        dictionary[key] = list()\n",
    "        dictionary[key].append(value)\n",
    "\n",
    "def safe_insert_dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = {}\n",
    "    if value not in dictionary[key]:\n",
    "        dictionary[key][value] = 0\n",
    "\n",
    "def line_counts(dictionary):\n",
    "    for key in dictionary:\n",
    "        print(key, len(dictionary[key]))\n",
    "        \n",
    "def getfileOwner(file):\n",
    "    name = file.split('.')[0]\n",
    "    for i in range(0, len(name)):\n",
    "        if name[i].isdigit():\n",
    "            name = name [:i]\n",
    "            break\n",
    "    return name.upper()\n",
    "\n",
    "\n",
    "def print_quotegen(quote_gen):\n",
    "    for k,v  in quote_gen.items():\n",
    "        print(k)\n",
    "        print('\\t',[ (k2,v2) for k2,v2  in v.items()])\n",
    "        \n",
    "def load_quotegen(person):\n",
    "    return pickle.load(open(person + '.pkl', 'rb') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAVID 2446\n",
      "DIEGO 3260\n",
      "ERIC 32224\n",
      "GWYN 21457\n",
      "JETT 5554\n",
      "MARS 23434\n",
      "MILES 15062\n",
      "MILO 34714\n",
      "PARSA 9714\n"
     ]
    }
   ],
   "source": [
    "quote_dict = {}\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    #not a base file\n",
    "    if \"_\" in file:\n",
    "        continue\n",
    "    owner = getfileOwner(file)\n",
    "    f = open(file, 'r', encoding=\"utf-8\")\n",
    "    lines = f.read()\n",
    "    lines = lines.split(\"\\n\")\n",
    "    for l in lines:\n",
    "        if l == \"\":\n",
    "            continue\n",
    "        safe_insert_list(quote_dict, owner, l)\n",
    "    f.close()\n",
    "for k in quote_dict:\n",
    "    print(k, len(quote_dict[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with quotegen DAVID\n",
      "Done with quotegen DIEGO\n",
      "Done with quotegen ERIC\n",
      "Done with quotegen GWYN\n",
      "Done with quotegen JETT\n",
      "Done with quotegen MARS\n",
      "Done with quotegen MILES\n",
      "Done with quotegen MILO\n",
      "Done with quotegen PARSA\n"
     ]
    }
   ],
   "source": [
    "def make_quotegen(person='PARSA'):   \n",
    "    quote_gen = {}\n",
    "\n",
    "    for sentence in quote_dict[person]:\n",
    "        token = nltk.word_tokenize(sentence)\n",
    "        for w1, w2, w3, w4 in ngrams(token, 4, pad_left = True, pad_right=True):\n",
    "            safe_insert_dict(quote_gen, (w1, w2, w3), w4)\n",
    "            quote_gen[(w1, w2, w3)][w4] += 1\n",
    "    \n",
    "    for w1_w2_w3 in quote_gen:\n",
    "        total_count = float(sum(quote_gen[w1_w2_w3].values()))\n",
    "        for w4 in quote_gen[w1_w2_w3]:\n",
    "            quote_gen[w1_w2_w3][w4] /= total_count\n",
    "\n",
    "    return quote_gen\n",
    "\n",
    "for person in quote_dict:\n",
    "    q = make_quotegen(person)\n",
    "    pickle.dump(q, open(person + '.pkl', 'wb') )\n",
    "    print(\"Done with quotegen \" + person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(person):\n",
    "    quote_gen = load_quotegen(person)\n",
    "    text = [None,None,None]\n",
    "    sentence_finished = False\n",
    "    while not sentence_finished:\n",
    "        r = random.random()\n",
    "        accumulator = .0\n",
    "\n",
    "        for word in quote_gen[tuple(text[-3:])].keys():\n",
    "            accumulator += quote_gen[tuple(text[-3:])][word]\n",
    "\n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "\n",
    "        if text[-3:] == [None,None,None]:\n",
    "            sentence_finished = True\n",
    "\n",
    "    return ' '.join([t for t in text if t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsa: yeah but playing league at all means youre buried under 10 miles of overwatch shit\n",
      "Parsa: and ill be honest , I thought she was a support\n",
      "Parsa: No I ’ m playing smash at milos house\n",
      "Parsa: how vile\n",
      "Parsa: yeah\n",
      "Parsa: youre playing with a bard , monk , and another fighter\n",
      "Parsa: It ’ s like setting the pendulum\n",
      "Parsa: friday\n",
      "Parsa: it does n't reflect on how you lead\n",
      "Parsa: or must he remain destitute and teamless\n",
      "Parsa: Miles collectors cache particles\n",
      "Parsa: Concede\n",
      "Parsa: I ’ m all in for extermination\n",
      "Parsa: there is no skill in dota . and the game has a high skill barrier to entry ?\n",
      "Parsa: and izoldi is actually trapped in the gem in the sword 's crossguard or pommel\n",
      "Parsa: EASY\n",
      "Parsa: i do n't care enough to send in a ballot\n",
      "Parsa: give me back my Beijing air\n",
      "Parsa: fucking cancer hero\n",
      "Parsa: the whole point is to make the 4 sets of gear i requested\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(\"Parsa: \" + generate_sentence('PARSA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in names:\n",
    "    for i in range(20):\n",
    "        print(n + \": \" + generate_sentence(n))\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(quote_dict, open('quotes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
